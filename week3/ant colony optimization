Week 3
Particle Swarm Optimization for Function Optimization by Abhay N Y

import numpy as np
import random
import matplotlib.pyplot as plt

# Set seeds for reproducibility
random.seed(42)
np.random.seed(42)

# --- 1. Objective Function ---

def sphere_function(position):
    """
    The classic Sphere function (f(x) = sum(x^2)), used for minimization.
    The global minimum is f(x)=0 at x=[0, 0, ..., 0].
    """
    # Ensures the input is treated as a NumPy array for vectorized operation
    return np.sum(position**2)

# --- 2. PSO Algorithm Implementation ---

def pso_optimizer(
    objective_func,
    num_particles=30,
    dimensions=2,
    search_range=(-10, 10),
    max_iterations=100,
    w=0.729,   # Inertia Weight (W)
    c1=1.4944, # Cognitive Constant (C1)
    c2=1.4944  # Social Constant (C2)
):
    """
    Particle Swarm Optimization (PSO) algorithm for continuous optimization.

    Args:
        objective_func (callable): The function to minimize.
        num_particles (int): Number of particles (S).
        dimensions (int): Dimensionality of the search space.
        search_range (tuple): (min, max) bounds for particle positions.
        max_iterations (int): Maximum number of generations.
        w (float): Inertia weight.
        c1 (float): Cognitive constant.
        c2 (float): Social constant.
    """
    min_bound, max_bound = search_range
    
    # 1. Initialize particle positions and velocities (x_i and v_i)
    # Positions: [num_particles, dimensions]
    positions = np.random.uniform(min_bound, max_bound, (num_particles, dimensions))
    # Velocities: [num_particles, dimensions]
    velocities = np.random.uniform(-1, 1, (num_particles, dimensions))

    # 2. Initialize Personal Best (PBest_i)
    pbest_positions = positions.copy()
    pbest_scores = np.array([objective_func(p) for p in positions])

    # 3. Initialize Global Best (GBest)
    gbest_index = np.argmin(pbest_scores)
    gbest_position = pbest_positions[gbest_index].copy()
    gbest_score = pbest_scores[gbest_index]

    history = [(gbest_score, gbest_position)]

    print(f"Starting PSO for {dimensions} dimensions with {num_particles} particles...")
    print(f"Initial GBest Score: {gbest_score:.4f}")

    for iteration in range(max_iterations):
        # --- Phase 1: Update PBest Positions ---
        for i in range(num_particles):
            current_score = objective_func(positions[i])

            # Check if current position is better than particle's personal best
            if current_score < pbest_scores[i]:
                pbest_scores[i] = current_score
                pbest_positions[i] = positions[i].copy()
        
        # --- Update GBest (Global Best) ---
        # Find the overall best position among all PBest's
        current_gbest_index = np.argmin(pbest_scores)
        current_gbest_score = pbest_scores[current_gbest_index]
        
        # Update GBest only if a better PBest was found
        if current_gbest_score < gbest_score:
            gbest_score = current_gbest_score
            gbest_position = pbest_positions[current_gbest_index].copy()

        # Record history for convergence plot
        history.append((gbest_score, gbest_position.copy()))

        # --- Phase 2: Update Velocity and Position ---
        
        # Generate two sets of random numbers R1 and R2
        r1 = np.random.rand(num_particles, dimensions) # Random_1
        r2 = np.random.rand(num_particles, dimensions) # Random_2

        # 1. Inertia component: W * v_i^t
        inertia_comp = w * velocities

        # 2. Cognitive component (PBest influence): C1 * r1 * (PBest_i - x_i^t)
        cognitive_comp = c1 * r1 * (pbest_positions - positions)

        # 3. Social component (GBest influence): C2 * r2 * (GBest - x_i^t)
        # NumPy handles broadcasting of the 1D gbest_position to the 2D positions matrix
        social_comp = c2 * r2 * (gbest_position - positions)

        # Update velocity: v_i^{t+1} = Inertia + Cognitive + Social
        velocities = inertia_comp + cognitive_comp + social_comp

        # Update position: x_i^{t+1} = x_i^t + v_i^{t+1}
        positions = positions + velocities

        # Apply position constraints (clipping to search space)
        positions = np.clip(positions, min_bound, max_bound)

        print(f"Iteration {iteration+1}/{max_iterations}: GBest Score = {gbest_score:.4e}")

    return gbest_position, gbest_score, history

# --- 3. Example Usage and Visualization ---

def run_pso_example():
    # Set up PSO parameters
    search_range = (-5.12, 5.12) # Common range for Sphere function
    max_iter = 100

    # Run the PSO solver
    best_position, best_score, history = pso_optimizer(
        objective_func=sphere_function,
        num_particles=30,
        dimensions=2, # Using 2D for simple visualization
        search_range=search_range,
        max_iterations=max_iter
    )

    print("\n--- Results ---")
    print(f"Objective Function: Sphere Function")
    print(f"Best Position Found: {best_position}")
    print(f"Minimum Score (Fitness): {best_score:.6e}")

    # --- Visualization ---

    # Extract scores for convergence plot
    scores = [item[0] for item in history]
    
    plt.figure(figsize=(10, 5))
    
    # Plot 1: Convergence History
    plt.subplot(1, 2, 1)
    plt.plot(range(len(scores)), scores, color='darkorange', linewidth=2)
    plt.title('PSO Convergence History')
    plt.xlabel('Iteration')
    plt.ylabel('Global Best Score (Log Scale)', color='darkorange')
    plt.yscale('log') # Use log scale for better visualization of minimization
    plt.grid(True, which="both", ls="--")

    # Plot 2: Particle movement (only for 2D problems)
    if history and len(history[0][1]) == 2:
        plt.subplot(1, 2, 2)
        
        # Create a contour plot of the objective function
        x = np.linspace(search_range[0], search_range[1], 100)
        y = np.linspace(search_range[0], search_range[1], 100)
        X, Y = np.meshgrid(x, y)
        
        # Calculate Z values for the Sphere function across the grid
        Z = np.array([[sphere_function(np.array([X[i, j], Y[i, j]])) for j in range(100)] for i in range(100)])
        
        plt.contourf(X, Y, Z, levels=50, cmap='viridis')
        plt.colorbar(label='Function Value')

        # Plot the final best position
        plt.plot(best_position[0], best_position[1], 'r*', markersize=15, label='Final GBest')
        plt.title('2D Search Space Visualization')
        plt.xlabel('Dimension 1 (X)')
        plt.ylabel('Dimension 2 (Y)')
        plt.legend()

    plt.tight_layout()
    plt.show()

# Execute the example
if __name__ == '__main__':
    run_pso_example()
